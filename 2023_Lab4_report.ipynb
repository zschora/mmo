{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQlcDy9BC5bE"
      },
      "source": [
        "# Методы машинного обучения – Лабораторная работа №4\n",
        "\n",
        "# Нейронные сети MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKlRxa2EKcTu"
      },
      "source": [
        "Импортируем необходимые библиотеки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCNmPhYuurZN"
      },
      "outputs": [],
      "source": [
        "# !pip install -q tfds-nightly\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCY8JVP9GRqc"
      },
      "source": [
        "### Бинарная классификация при помощи TensorFlow\n",
        "\n",
        "__Бинарная (двоичная) классификация__ (binary classification) — это задача классификации элементов заданного набора данных в два класса.\n",
        "\n",
        "Создадим синтетический набор данных при помощи функции `make_circles`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4mZ8kXVGRqc"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "n_samples = 1000\n",
        "X, y = make_circles(n_samples,\n",
        "                    noise = 0.03,\n",
        "                    random_state = 42)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RXovTkSGRqd"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[:,0], X[:,1], c = y, cmap = plt.cm.RdYlBu)\n",
        "plt.axis('equal');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для визуализации областей принятия решения будем использовать следующую функцию (аналогичная функция определена в библиотеке `mlxtend`):"
      ],
      "metadata": {
        "id": "t5b0w8c-3pXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tycU3fSOGRqe"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(model, X, y):\n",
        "    # Найдем диапазоны изменения по осям и построим сетку\n",
        "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                         np.linspace(y_min, y_max, 100))\n",
        "    # Набор данных для прогнозирования\n",
        "    X_in = np.c_[xx.ravel(), yy.ravel()] \n",
        "    # Прогноз при помощи обученной модели\n",
        "    y_pred = model.predict(X_in)\n",
        "    # Проверка мультиклассовости\n",
        "    if len(y_pred[1]) > 1:\n",
        "        # мультиклассовая классификация\n",
        "        # изменяем форму прогноза для визуализации \n",
        "        y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
        "    else:\n",
        "        # бинарная классификация \n",
        "        y_pred = np.round(y_pred).reshape(xx.shape)\n",
        "    # Рисуем границу решения\n",
        "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим нейронную сеть с одним слоем из одного нейрона и попробуем обучить ее бинарной классификации (для этого функция активации в выходном слое будет сигмоидой):"
      ],
      "metadata": {
        "id": "XdBJthbz4NPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmTCnWBcGRqe"
      },
      "outputs": [],
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')])\n",
        "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
        "                metrics = ['accuracy'])\n",
        "model_1.fit(X, y, epochs = 5);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нейронная сеть не обучается, а области принятия решения выглядят так:"
      ],
      "metadata": {
        "id": "rkYN_Cof5V28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3iFjyB-GRqf"
      },
      "outputs": [],
      "source": [
        "plot_decision_boundary(model_1, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем теперь использовать глубокую (многослойную) нейронную сеть с нелинейными функциями активации в скрытых слоях. Разобьем набор данных на обучающую и тестовую выборки: "
      ],
      "metadata": {
        "id": "jE232j845oDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0oC1IhCGRqg"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = X[:800], y[:800]\n",
        "X_test, y_test = X[800:], y[800:]\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0CVOqzDGRqg"
      },
      "outputs": [],
      "source": [
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation = 'relu'), \n",
        "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model_2.compile(loss= tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
        "                metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auug1y9QGRqh"
      },
      "outputs": [],
      "source": [
        "model_2.fit(X_train, y_train, epochs = 25, verbose = 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mlu5AsTKGRqh"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
        "print(f'Потери модели на тестовой выборке: {loss}')\n",
        "print(f'Доля верных ответов на тестовой выборке: {100*accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KUUu1nDGRqh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Обучающая выборка\")\n",
        "plot_decision_boundary(model_2, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Тестовая выборка\")\n",
        "plot_decision_boundary(model_2, X=X_test, y=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arPpw7dzGRqi"
      },
      "source": [
        "### Важность признаков\n",
        "\n",
        "Линейные алгоритмы машинного обучения строят модели, в которых прогноз представляет собой взвешенную сумму входных значений.\n",
        "\n",
        "Примеры таких алгоритмов включают линейную регрессию, логистическую регрессию и их расширения, добавляющие регуляризацию, такие как гребневая регрессия и эластичная сеть.\n",
        "\n",
        "Все эти алгоритмы находят набор коэффициентов для использования во взвешенной сумме, чтобы сделать прогноз. Эти же коэффициенты можно использовать в качестве предварительной оценки важности признаков.\n",
        "\n",
        "Загрузим набор данных Ирисы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB8EvIk5vDFY"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load(\"iris\", split='train')\n",
        "df = tfds.as_dataframe(ds)\n",
        "for i in range(4):\n",
        "    df['V'+str(i)] = df['features'].apply([lambda x:x[i]])\n",
        "df.drop(columns=['features'],inplace=True)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBM-bSvsDZgM"
      },
      "source": [
        "В наборе данных 150 записей, 4 независимых признака и метки классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTwVnLapvLbP"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfbCnAOmvo_n"
      },
      "source": [
        "В наборе данных отсутствуют пропущенные значения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7APqhK-vz6X"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все столбцы числовые:"
      ],
      "metadata": {
        "id": "ROR2Jha9IKJt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IytoZGrGRqk"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сформируем массивы из признаков и меток класса:"
      ],
      "metadata": {
        "id": "GJvEYOX9ITyp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPE7mb34GRqk"
      },
      "outputs": [],
      "source": [
        "X = np.array(df.drop('label', axis=1))\n",
        "y = np.array(df['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим точки первых двух классов:"
      ],
      "metadata": {
        "id": "0z9FUXxi9pIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[ y<2 ]\n",
        "y = y[ y<2 ]"
      ],
      "metadata": {
        "id": "F8-nqxVv7SpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим и адаптируем слой нормализации для всех признаков:"
      ],
      "metadata": {
        "id": "p3RHkVB9Ic5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhV2PV7wGRqk"
      },
      "outputs": [],
      "source": [
        "feature_normalizer = tf.keras.layers.Normalization(axis=None,input_shape=(X.shape[1],)) \n",
        "feature_normalizer.adapt(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Построим нейронную сеть с одним выходным нейроном с функцией активации сигмоида для решения задачи логистической регрессии:"
      ],
      "metadata": {
        "id": "hwvRiN0KItBN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YAqR0XRGRql"
      },
      "outputs": [],
      "source": [
        "model_aux = tf.keras.Sequential([\n",
        "    feature_normalizer,\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_aux.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скомпилируем и обучим модель:"
      ],
      "metadata": {
        "id": "zhsv8q9LJJbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAHWf2n-GRql"
      },
      "outputs": [],
      "source": [
        "model_aux.compile(loss=tf.keras.losses.binary_crossentropy)\n",
        "model_aux.fit(X, y, epochs=1000, verbose=0);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на значения весов в выходном слое:"
      ],
      "metadata": {
        "id": "CABQZjBhJSNr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZR_86ezGRql"
      },
      "outputs": [],
      "source": [
        "model_aux.layers[1].kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FUvbHKVGRql"
      },
      "source": [
        "Веса в слое после обучения нейронной сети имеют значения, зависящие от случайных начальных значений, поэтому, вообще говоря, нужно строить несколько моделей и усреднять результаты.\n",
        "\n",
        "Более высокие значения весов (по абсолютному значению) чаще всего означают более высокую важность признаков.\n",
        "\n",
        "Таким образом, для определения важности признаков набора данных для бинарной классификации можно решать вспомогательную задачу построения и обучения нейронной сети для логистической регрессии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea4FLN13u0ER"
      },
      "source": [
        "### Задача класссификации\n",
        "\n",
        "Пусть имеется множество объектов, характеризующихся признаками и разделённых некоторым образом на классы.\n",
        "\n",
        "__Задача классификации__ — это задача построения алгоритма (функции), способного классифицировать произвольный объект из исходного пространства признаков, т.е. определять метку класса для этого объекта."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTgbNgA1TSFd"
      },
      "source": [
        "__Бинарная (двоичная) классификация__ (binary classification) — это задача классификации элементов заданного набора данных в два класса.\n",
        "\n",
        "Для бинарной классификации могут применяться методы многоклассовой классификации, а также ряд специализированных методов, например, логистическая регрессия.\n",
        "\n",
        "Задача классификации ирисов не является задачей бинарной классификации. Чтобы получить бинарную классификацию, оставим в наборе данных два первых класса ирисов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-V1-mh3GRqm"
      },
      "outputs": [],
      "source": [
        "X = X[y<2,:2]\n",
        "y = y[y<2]\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWhiVf9DZgS"
      },
      "source": [
        "Для разбиения набора данных на обучающую и тестовую выборки будем использовать функцию `train_test_split`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4CS6Gl6DZgn"
      },
      "outputs": [],
      "source": [
        "def train_test_split(X, y, test_ratio=0.2, seed=None):\n",
        "    \"\"\"возвращает X_train, X_test, y_train, y_test\"\"\"\n",
        "    assert X.shape[0] == y.shape[0], \\\n",
        "        \"Размер X должен быть равен размеру y\"\n",
        "    assert 0.0 <= test_ratio <= 1.0, \\\n",
        "        \"Неверное значение test_ratio\"\n",
        "\n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    shuffled_indexes = np.random.permutation(len(X))\n",
        "\n",
        "    test_size = int(len(X) * test_ratio)\n",
        "    test_indexes = shuffled_indexes[:test_size]\n",
        "    train_indexes = shuffled_indexes[test_size:]\n",
        "\n",
        "    X_train = X[train_indexes]\n",
        "    y_train = y[train_indexes]\n",
        "\n",
        "    X_test = X[test_indexes]\n",
        "    y_test = y[test_indexes]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ4v2N72GRqn"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_ratio=0.2, seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmnuKXhFDZgT"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x8LgJ79DZgi"
      },
      "source": [
        "### Глубокая нейронная сеть для задачи бинарной классификации\n",
        "\n",
        "Так как признаки набора имеют разные диапазоны изменения, используем слой нормализации, адаптированный ко всем независимым признакам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRfe-FwrDZgi"
      },
      "outputs": [],
      "source": [
        "feature_normalizer = tf.keras.layers.Normalization(axis=None,input_shape=(X.shape[1],)) \n",
        "feature_normalizer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPrecAIXDZgi"
      },
      "source": [
        "Создадим нейронную сеть со слоем нормализации, тремя скрытыми плотными слоями с 64  нейронами и функцией активации ReLu и выходным слоем из одного нейрона с функцией активации сигмоида:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkfQoTWeGRqo"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    feature_normalizer,\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnmcDukEGRqp"
      },
      "source": [
        "Используем в качестве функции потерь при работе с задачами бинарной классификации `binary_crossentropy`. В ходе обучения будем отслеживать показатель аккуратности (accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8br-0IfAGRqp"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.03),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5YnIwU2GRqp"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgBcfXtHGRqp"
      },
      "source": [
        "### Визуализация обучения модели "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwEMcXIIGRqq"
      },
      "outputs": [],
      "source": [
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = (18, 8)\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8irNKvv8GRqq"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(1, 4), history.history['loss'], label='Потери')\n",
        "plt.plot(np.arange(1, 4), history.history['accuracy'], label='Доля верных ответов')\n",
        "plt.title('Показатели качества нейронной сети', size=20)\n",
        "plt.xlabel('Эпохи', size=14)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FWTQ7uOeVNS"
      },
      "source": [
        "### Прогнозирование при помощи модели\n",
        "\n",
        "При помощи обученной нейронной сети получаем на выходе значения, которые можно интерпретировать как вероятности:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3a8MHelDZgU"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(X_test)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lggxbgsFGRqq"
      },
      "source": [
        "Эти вероятности можно преобразовать в прогнозируемые классы следующим образом (использовано пороговое значение 0.5):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGCeZCQyev5U"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array([1 if prob > 0.5 else 0 for prob in np.ravel(prediction)])\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj3XKkYGDZgU"
      },
      "source": [
        "Оценка модели на тестовой выборке выглядит так:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uwr9YMgDZgU"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VcMadxlGRqr"
      },
      "source": [
        "### Визуализация границы решения\n",
        "\n",
        "Граница решения для построенного классификатора:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_vqJAHwDZgX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Обучающая выборка\")\n",
        "plot_decision_boundary(model, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Тестовая выборка\")\n",
        "plot_decision_boundary(model, X=X_test, y=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALL5Xk9GRqs"
      },
      "source": [
        "### Показатели качества бинарной классификации\n",
        "\n",
        "Когда имеется всего два класса, то будем называть класс $c_{1}$ положительным классом, а класс $c_{2}$ отрицательным классом. Тогда матрица ошибок (confusion matrix) принимает вид:\n",
        "\n",
        "$$\\left(\\begin{array}{cc}\n",
        "TP & FN\\\\\n",
        "FP & TN\n",
        "\\end{array}\\right),$$\n",
        "\n",
        "где \n",
        "* $TP$ – (True Positives) – число корректно спрогнозированных точек в классе $c_{1}$ \n",
        "* $FN$ – (False Negatives) – число точек в классе $c_{1}$, ошибочно спрогнозированных в класс $c_{2}$\n",
        "* $FP$ – (False Positives) – число точек в классе $c_{2}$, ошибочно спрогнозированных в класс $c_{1}$\n",
        "* $TN$ – (True Negatives) – число корректно спрогнозированных точек в классе $c_{2}$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6OZFabRGRqs"
      },
      "source": [
        "Показатели $TN$, $FP$, $FN$ и $TP$ могут быть реализованы так:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL3UtZolGRqs"
      },
      "outputs": [],
      "source": [
        "def TN(y_true, y_predict):\n",
        "    assert len(y_true) == len(y_predict)\n",
        "    return np.sum((y_true == 0) & (y_predict == 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgfp9cx2GRqs"
      },
      "outputs": [],
      "source": [
        "def FP(y_true, y_predict):\n",
        "    assert len(y_true) == len(y_predict)\n",
        "    return np.sum((y_true == 0) & (y_predict == 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1ufGB5BGRqt"
      },
      "outputs": [],
      "source": [
        "def FN(y_true, y_predict):\n",
        "    assert len(y_true) == len(y_predict)\n",
        "    return np.sum((y_true == 1) & (y_predict == 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guk0UN_CGRqt"
      },
      "outputs": [],
      "source": [
        "def TP(y_true, y_predict):\n",
        "    assert len(y_true) == len(y_predict)\n",
        "    return np.sum((y_true == 1) & (y_predict == 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gL4OaTLGRqt"
      },
      "source": [
        "Матрица ошибок для бинарной классификации определяется так:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4QVqmaZGRqt"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(y_true, y_predict):\n",
        "    return np.array([\n",
        "        [TP(y_true, y_predict), FN(y_true, y_predict)],\n",
        "        [FP(y_true, y_predict), TN(y_true, y_predict)]\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDxypEQeGRqt"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AReWH9ugGRqu"
      },
      "source": [
        "Наряду с показателями $TP, TN, FP, FN$ могут быть вычислены показатели $TPR=\\frac{TP}{TP+FN}$ (доля корректно спрогнозированных положительных точек) и $FPR=\\frac{FP}{FP+TN}$ (доля ошибочно  спрогнозированных положительных точек):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5d3_T0bGRqv"
      },
      "outputs": [],
      "source": [
        "def tpr_score(y_true, y_predict):\n",
        "    tp = TP(y_true, y_predict)\n",
        "    fn = FN(y_true, y_predict)\n",
        "    try:\n",
        "        return tp / (tp + fn)\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def fpr_score(y_true, y_predict):\n",
        "    fp = FP(y_true, y_predict)\n",
        "    tn = TN(y_true, y_predict)\n",
        "    try:\n",
        "        return fp / (fp + tn)\n",
        "    except:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CkmeeJMGRqv"
      },
      "outputs": [],
      "source": [
        "tpr_score(y_test, y_pred), fpr_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Yls-NBDZgY"
      },
      "source": [
        "### ROC-анализ\n",
        "\n",
        "ROC-анализ (Receiver Operating Characteristic) – это популярная стратегия оценки производительности бинарных классификаторов. Для ROC-анализа нужен не только прогноз меток класса, но и значения т.н. скоринговой функции для каждой точки в тестовом наборе. В качестве значений скоринговой функции можно взять вероятности, возвращаемые нейронной сетью:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjxGTjM2DZgY"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(X)\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcE7nTWfDZgZ"
      },
      "source": [
        "Пусть $S\\left(\\mathbf{\\overline{x}}_{i}\\right)$ – это значение скоринговой функции для точки $\\mathbf{\\overline{x}}_{i}$ и пусть минимальное и максимальное значения скоринговой функции на наборе данных $\\mathbf{D}$ равны $\\rho^{min}=\\min_{i}S\\left(\\mathbf{\\overline{x}}_{i}\\right)$, $\\,\\rho^{max}=\\max_{i}S\\left(\\mathbf{\\overline{x}}_{i}\\right)$.\n",
        "\n",
        "Скоринговая функция применяется для бинарной классификации точек набора данных следующим образом: выбирается некоторый порог отсечения (threshold) и если скоринговая функция принимает на точке значение выше порога отсечения, то точка классифицируется как положительная, иначе, как отрицательная. Далее для каждого значения $\\rho\\in\\left[\\rho^{min},\\rho^{max}\\right]$ определяем множество положительных точек $\\mathbf{R_{1}}\\left(\\rho\\right)=\\left\\{ \\mathbf{\\overline{x}}_{i}\\in\\mathbf{D}:S\\left(\\mathbf{\\overline{x}}_{i}\\right)>\\rho\\right\\}$  и вычисляем показатели $TPR$ и $FPR$, чтобы получить новую точку на ROC кривой. \n",
        "\n",
        "Показатель $FPR$ откладывается вдоль оси x, а показатель $TPR$ – вдоль оси y. В результате получаем ROC кривую (кривую Лоренца).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfcb6kThGRqw"
      },
      "outputs": [],
      "source": [
        "def true_false_positive(threshold_vector, y_test):\n",
        "    true_positive = np.equal(threshold_vector, 1) & np.equal(y_test, 1)\n",
        "    true_negative = np.equal(threshold_vector, 0) & np.equal(y_test, 0)\n",
        "    false_positive = np.equal(threshold_vector, 1) & np.equal(y_test, 0)\n",
        "    false_negative = np.equal(threshold_vector, 0) & np.equal(y_test, 1)\n",
        "\n",
        "    tpr = true_positive.sum() / (true_positive.sum() + false_negative.sum())\n",
        "    fpr = false_positive.sum() / (false_positive.sum() + true_negative.sum())\n",
        "\n",
        "    return tpr, fpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COcwlN53GRqx"
      },
      "outputs": [],
      "source": [
        "def roc_from_scratch(probabilities, y_test, partitions=100):\n",
        "    roc = np.array([])\n",
        "    for i in range(partitions + 1):\n",
        "        \n",
        "        threshold_vector = np.greater_equal(probabilities, i / partitions).astype(int)\n",
        "        tpr, fpr = true_false_positive(threshold_vector, y_test)\n",
        "        roc = np.append(roc, [fpr, tpr])\n",
        "        \n",
        "    return roc.reshape(-1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRBP9E5OGRqx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "ROC = roc_from_scratch(prediction.reshape(-1),y,partitions=50)\n",
        "#plt.scatter(ROC[:,0],ROC[:,1],color='#0F9D58',s=100)\n",
        "plt.plot(ROC[:,0],ROC[:,1],color='#0F9D58',lw=5)\n",
        "plt.title('ROC кривая',fontsize=20)\n",
        "plt.xlabel('Показатель FPR (False Positive Rate)',fontsize=16)\n",
        "plt.ylabel('Показатель TPR (True Positive Rate)',fontsize=16);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MszTzK1ADZga"
      },
      "source": [
        "В случае идеального бинарного классификатора верхней левой точкой ROC кривой является точка $\\left(0,\\,1\\right)$, соответствующая значениям $FPR=0$ и $TPR=1$, т.е. у классификатора нет ложно положительных точек и правильно классифицированы все положительные точки (отсюда вытекает, что правильно классифицированы и все отрицательные точки). \n",
        "\n",
        "Таким образом, ROC-кривая показывает, в какой степени классификатор дает более высокую оценку положительным точкам по сравнению с отрицательными точками. Идеальный классификатор оценивает все положительные точки выше, чем отрицательные. Таким образом, чем ближе ROC кривая к идеальному случаю, тем лучше классификатор. \n",
        "\n",
        "Площадь под ROC кривой, обозначаемая $AUC$, может быть использована как мера качества классификатора. Так как общая площадь квадрата равна $1$, показатель $AUC$ находится в интервале $\\left[0,\\,1\\right]$ (чем больше, тем лучше). \n",
        "\n",
        "Для вычисления площади под кривой можно использовать метод трапеций или иной численный метод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojv5wSvCDZga"
      },
      "source": [
        "### Глубокая нейронная сеть для задачи многоклассовой классификации\n",
        "\n",
        "Вернемся к исходному набору данных Ирисы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OgI6BUPDZgb"
      },
      "outputs": [],
      "source": [
        "df = tfds.as_dataframe(ds)\n",
        "for i in range(4):\n",
        "    df['V'+str(i)] = df['features'].apply([lambda x:x[i]])\n",
        "df.drop(columns=['features'],inplace=True)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpqkVHfXGRqy"
      },
      "outputs": [],
      "source": [
        "X = np.array(df.drop('label', axis=1))\n",
        "y = np.array(df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkFllGUAGRqy"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_ratio=0.2, seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF7NXqxzGRqy"
      },
      "outputs": [],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDMKYNYxGRqy"
      },
      "outputs": [],
      "source": [
        "def to_one_hot(labels, dimension=3):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uSTCJ6fGRqy"
      },
      "outputs": [],
      "source": [
        "y_train = to_one_hot(y_train)\n",
        "y_test = to_one_hot(y_test)\n",
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3bx2g63GRqz"
      },
      "outputs": [],
      "source": [
        "feature_normalizer = tf.keras.layers.Normalization(axis=None,input_shape=(X.shape[1],)) \n",
        "feature_normalizer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fluWESGlGRqz"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    feature_normalizer,\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28YpkeFzGRqz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cxnpIEEGRqz"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=20,\n",
        "                    # уровень выводимой информации\n",
        "                    verbose=1,\n",
        "                    # проверка (валидация) на 20% обучающих данных\n",
        "                    validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isaAobV_GRqz"
      },
      "outputs": [],
      "source": [
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Потери на обучающей выборке\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Потери на тестовой выборке\")\n",
        "plt.title(\"Функция потерь при обучении модели\")\n",
        "plt.xlabel(\"Эпохи обучения\")\n",
        "plt.ylabel(\"Функция потерь\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание бинарного набора данных\n",
        "\n",
        "Загрузим набор данных с информацией о качестве вина на основе физико-химических тестов."
      ],
      "metadata": {
        "id": "qM8mtjIpkHmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tfds.load(\"wine_quality\", split='train')\n",
        "df = tfds.as_dataframe(ds)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "URSLpOrgkeOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим в наборе данных два независимых признака `features/density` и `features/alcohol` и метки классов `quality`,  убрав из названий признаков строку `features/`:"
      ],
      "metadata": {
        "id": "hm7UyKNVkyOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['features/density','features/alcohol','quality']]\n",
        "df.columns = ['density','alcohol','quality']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KT5LWgqOk0AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим количество записей с различными значениями признака `quality`:"
      ],
      "metadata": {
        "id": "l1CyxNf0lDLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['quality'].unique()"
      ],
      "metadata": {
        "id": "BMEGziw3lE4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['quality'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "qq4F6G0olS9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объявим винами высшего качества вина с индексом качестве более или равным 6:"
      ],
      "metadata": {
        "id": "6v8_EG-ale-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['top'] = [1 if quality >= 6 else 0 for quality in df['quality']]\n",
        "df.drop('quality', axis=1, inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YnEvZXCMlhV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Если нейронная сеть не обучается...\n",
        "\n",
        "* Проверить отсутствие ошибок в коде – могут быть ошибки, которые не создают исключений, но не дают нейронной сети обучиться\n",
        "* Проверить, что нейронная сеть формирует выход на каких-нибудь тестовых данных. Убедиться, что на других тестовых данных выход будет отличаться.\n",
        "* Проверьте, что входные данные нормализованы\n",
        "* Поработайте с набором данных – уберите выбросы, попробуйте обучить сеть не на всем наборе, а на случайной выборке\n",
        "* Измените параметры обучения – поменяйте оптимизатор, начальный шаг обучения и т.п.\n",
        "* Измените способ начальной инициализации весов в скрытых слоях, например:\n",
        "`kernel_initializer='he_normal'`\n",
        "* Измените параметры (в т.ч. по умолчанию) в методе `fit()`, например, количество эпох, размер пакета `batch_size` и пр.\n"
      ],
      "metadata": {
        "id": "_FiSqAEsPfWL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvrOTmXEBUVS"
      },
      "source": [
        "#### Задание (10 баллов)\n",
        "\n",
        "Для закрепленного за Вами варианта лабораторной работы:\n",
        "\n",
        "1.\tЗагрузите заданный в индивидуальном задании набор данных из Tensorflow Datasets, включая указанные в задании независимые признаки и метку класса.\n",
        "\n",
        "2.\tВизуализируйте точки набора данных на плоскости с координатами, соответствующими двум независимым признакам, отображая точки различных классов разными цветами. Подпишите оси и рисунок, создайте легенду для классов набора данных.\n",
        "\n",
        "3.\tЕсли признак с метками классов содержит более двух классов, то объедините некоторые классы, чтобы получить набор для бинарной классификации. Объединяйте классы таким образом, чтобы положительный и отрицательный классы были сопоставимы по количеству точек. \n",
        "\n",
        "4.\tРазбейте набор данных из двух признаков и меток класса на обучающую и тестовую выборки. Постройте нейронную сеть с нормализующим слоем и параметрами, указанными в индивидуальном задании, для бинарной классификации и обучите ее на обучающей выборке. Оцените качество бинарной классификации при помощи матрицы ошибок для тестовой выборки.\n",
        "\n",
        "5.\tВизуализируйте границы принятия решений построенной нейронной сетью на обучающей и тестовой выборках.\n",
        "\n",
        "6.\tВизуализируйте ROC-кривую для построенного классификатора и вычислите площадь под ROC-кривой методом трапеций или иным методом.\n",
        "\n",
        "7.\tОбучите на полном наборе данных нейронную сеть с одним слоем и одним выходным нейроном с функцией активации сигмоида и определите дополнительный признак, отличный от указанных в задании двух независимых признаков, принимающий непрерывные значения и являющийся важным по абсолютному значению веса в обученной нейронной сети. \n",
        "\n",
        "8.\tВизуализируйте точки набора данных в трехмерном пространстве с координатами, соответствующими трем независимым признакам, отображая точки различных классов разными цветами. Подпишите оси и рисунок, создайте легенду для классов набора данных.\n",
        "\n",
        "9.\tРазбейте полный набор данных на обучающую и тестовую выборки. Постройте нейронную сеть с нормализующим слоем и параметрами, указанными в индивидуальном задании, для многоклассовой классификации и обучите ее на обучающей выборке.\n",
        "\n",
        "10.\tПостройте кривые обучения в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ul5EHxsDZgp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}